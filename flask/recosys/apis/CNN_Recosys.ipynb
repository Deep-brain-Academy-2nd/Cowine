{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ratings = pd.read_csv('./data/ratingData.csv',)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['wineCode'] = ratings['wineCode'].astype(int)\n",
    "ratings['age'] = ratings['age'].astype(int)\n",
    "ratings['sex'] = ratings['sex'].astype(int)\n",
    "ratings['rating\t'] = ratings['rating'].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>wineCode</th>\n",
       "      <th>rating</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>rating\\t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hihi</td>\n",
       "      <td>170389</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hihi</td>\n",
       "      <td>170388</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hihi</td>\n",
       "      <td>170382</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hihi</td>\n",
       "      <td>170270</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hihi</td>\n",
       "      <td>170265</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hihi</td>\n",
       "      <td>170241</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hihi</td>\n",
       "      <td>170242</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>beDeveloper</td>\n",
       "      <td>170389</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>beDeveloper</td>\n",
       "      <td>170388</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>beDeveloper</td>\n",
       "      <td>170382</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>beDeveloper</td>\n",
       "      <td>170270</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>beDeveloper</td>\n",
       "      <td>170265</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>beDeveloper</td>\n",
       "      <td>170271</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pizzalove</td>\n",
       "      <td>170212</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pizzalove</td>\n",
       "      <td>170376</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pizzalove</td>\n",
       "      <td>170212</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pizzalove</td>\n",
       "      <td>170389</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pizzalove</td>\n",
       "      <td>170272</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>deepbrain</td>\n",
       "      <td>170270</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>deepbrain</td>\n",
       "      <td>170331</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>deepbrain</td>\n",
       "      <td>170334</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>deepbrain</td>\n",
       "      <td>170332</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>deepbrain</td>\n",
       "      <td>170331</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>deepbrain</td>\n",
       "      <td>170310</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>rapperDeveloper</td>\n",
       "      <td>170388</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>rapperDeveloper</td>\n",
       "      <td>170376</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>rapperDeveloper</td>\n",
       "      <td>170389</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>rapperDeveloper</td>\n",
       "      <td>170331</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>rapperDeveloper</td>\n",
       "      <td>170111</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>groot</td>\n",
       "      <td>170373</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>groot</td>\n",
       "      <td>170299</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>groot</td>\n",
       "      <td>170376</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>groot</td>\n",
       "      <td>170331</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>groot</td>\n",
       "      <td>170209</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>groot2</td>\n",
       "      <td>170111</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>groot2</td>\n",
       "      <td>170388</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>groot2</td>\n",
       "      <td>170331</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>groot2</td>\n",
       "      <td>170332</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>groot2</td>\n",
       "      <td>170212</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             userId  wineCode  rating  sex  age  rating\\t\n",
       "0              hihi    170389       3    2    1         3\n",
       "1              hihi    170388       3    2    1         3\n",
       "2              hihi    170382       5    2    1         5\n",
       "3              hihi    170270       1    2    1         1\n",
       "4              hihi    170265       2    2    1         2\n",
       "5              hihi    170241       1    2    1         1\n",
       "6              hihi    170242       4    2    1         4\n",
       "7       beDeveloper    170389       1    2    3         1\n",
       "8       beDeveloper    170388       2    2    3         2\n",
       "9       beDeveloper    170382       3    2    3         3\n",
       "10      beDeveloper    170270       4    2    3         4\n",
       "11      beDeveloper    170265       2    2    3         2\n",
       "12      beDeveloper    170271       1    2    3         1\n",
       "13        pizzalove    170212       4    2    2         4\n",
       "14        pizzalove    170376       3    2    2         3\n",
       "15        pizzalove    170212       1    2    2         1\n",
       "16        pizzalove    170389       3    2    2         3\n",
       "17        pizzalove    170272       5    2    2         5\n",
       "18        deepbrain    170270       3    2    5         3\n",
       "19        deepbrain    170331       2    2    5         2\n",
       "20        deepbrain    170334       3    2    5         3\n",
       "21        deepbrain    170332       4    2    5         4\n",
       "22        deepbrain    170331       5    2    5         5\n",
       "23        deepbrain    170310       1    2    5         1\n",
       "24  rapperDeveloper    170388       2    1    3         2\n",
       "25  rapperDeveloper    170376       5    1    3         5\n",
       "26  rapperDeveloper    170389       4    1    3         4\n",
       "27  rapperDeveloper    170331       2    1    3         2\n",
       "28  rapperDeveloper    170111       1    1    3         1\n",
       "29            groot    170373       2    1    1         2\n",
       "30            groot    170299       3    1    1         3\n",
       "31            groot    170376       3    1    1         3\n",
       "32            groot    170331       2    1    1         2\n",
       "33            groot    170209       5    1    1         5\n",
       "34           groot2    170111       3    1    3         3\n",
       "35           groot2    170388       4    1    3         4\n",
       "36           groot2    170331       3    1    3         3\n",
       "37           groot2    170332       2    1    3         2\n",
       "38           groot2    170212       3    1    3         3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test 분리\n",
    "from skearn.utis import shuffe\n",
    "TRAIN_SIZE = 0.75\n",
    "ratings = shuffe(ratings)\n",
    "cutoff = int(TRAIN_SIZE * en(ratings))\n",
    "ratings_train = ratings.ioc[:cutoff]\n",
    "ratings_test = ratings.ioc[cutoff:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>wineCode</th>\n",
       "      <th>rating</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>rating\\t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>groot</td>\n",
       "      <td>170373</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pizzalove</td>\n",
       "      <td>170212</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>rapperDeveloper</td>\n",
       "      <td>170331</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>groot2</td>\n",
       "      <td>170332</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>rapperDeveloper</td>\n",
       "      <td>170111</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             userId  wineCode  rating  sex  age  rating\\t\n",
       "29            groot    170373       2    1    1         2\n",
       "15        pizzalove    170212       1    2    2         1\n",
       "27  rapperDeveloper    170331       2    1    3         2\n",
       "37           groot2    170332       2    1    3         2\n",
       "28  rapperDeveloper    170111       1    1    3         1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorfow as tf\n",
    "from tensorfow.keras import ayers\n",
    "from tensorfow.keras.modes import Mode\n",
    "from tensorfow.keras.ayers import Input, Embedding, Dot, Add, Fatten\n",
    "from tensorfow.keras.reguarizers import 2\n",
    "from tensorfow.keras.optimizers import SGD, Adam, Adamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = ratings.userId.unique()\n",
    "sex = ratings.userId.unique()\n",
    "K = 200                             # atent factor 수 \n",
    "mu = ratings_train.rating.mean()    # 전체 평균 \n",
    "M = ratings.userId.unique() + 1       # Number of users\n",
    "N = ratings.wineCode.unique() + 1      # Number of movies\n",
    "\n",
    "# Defining RMSE measure\n",
    "def RMSE(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = Input(shape=(1, ))\n",
    "item = Input(shape=(1, ))\n",
    "P_embedding = Embedding(M, K, embeddings_reguarizer=2())(user)\n",
    "Q_embedding = Embedding(N, K, embeddings_reguarizer=2())(item)\n",
    "user_bias = Embedding(M, 1, embeddings_reguarizer=2())(user)\n",
    "item_bias = Embedding(N, 1, embeddings_reguarizer=2())(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorfow.keras.ayers import Dense, Concatenate, Activation\n",
    "P_embedding = Fatten()(P_embedding)\n",
    "Q_embedding = Fatten()(Q_embedding)\n",
    "user_bias = Fatten()(user_bias)\n",
    "item_bias = Fatten()(item_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = Input(shape=(1, ))\n",
    "age_embedding = Embedding(age, 3, embeddings_reguarizer=2())(age)\n",
    "age_ayer = Fatten()(age_embedding)\n",
    "sex = Input(shape=(1, ))\n",
    "sex_embedding = Embedding(sex, 3, embeddings_reguarizer=2())(sex)\n",
    "sex_ayer = Fatten()(sex_embedding)\n",
    "R = Concatenate()([P_embedding, Q_embedding, user_bias, item_bias, age_ayer, sex_ayer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "R = Dense(\"차원수\")(R)\n",
    "R = Activation('inear')(R)\n",
    "R = Dense(256)(R)\n",
    "R = Activation('inear')(R)\n",
    "R = Dense(1)(R)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = Mode(inputs=[user, item, age,sex], outputs=R)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 1, 200)       188800      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 1, 200)       336600      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 1, 1)         944         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, 1, 1)         1683        ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)        (None, 1, 3)         63          ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 200)          0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 200)          0           ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 1)            0           ['embedding_2[0][0]']            \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 1)            0           ['embedding_3[0][0]']            \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 3)            0           ['embedding_4[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 405)          0           ['flatten[0][0]',                \n",
      "                                                                  'flatten_1[0][0]',              \n",
      "                                                                  'flatten_2[0][0]',              \n",
      "                                                                  'flatten_3[0][0]',              \n",
      "                                                                  'flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 2048)         831488      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 2048)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1024)         2098176     ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 1024)         0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 512)          524800      ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 512)          0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 256)          131328      ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 256)          0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 1)            257         ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,114,139\n",
      "Trainable params: 4,114,139\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mode.compie(\n",
    "  oss=RMSE,\n",
    "  optimizer=SGD(),\n",
    "  metrics=[RMSE]\n",
    ")\n",
    "mode.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cabacks = [\n",
    "    tf.keras.cabacks.ModeCheckpoint(\n",
    "        fiepath=\"../checkpoints/mymode_{epoch}\",\n",
    "        save_best_ony=True,  \n",
    "        monitor=\"va_RMSE\",\n",
    "        verbose=1,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_path = \"../checkpoints/epoch_{epoch:03d}.ckpt\"\n",
    "# # 모델의 가중치를 저장하는 콜백 만들기\n",
    "# cp_caback = tf.keras.cabacks.ModeCheckpoint(fiepath=checkpoint_path,\n",
    "#                                                  save_weights_ony=True,\n",
    "#                                                  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 5.3913 - RMSE: 1.1231\n",
      "Epoch 00001: val_RMSE improved from inf to 1.12457, saving model to ../checkpoints\\mymodel_1\n",
      "INFO:tensorflow:Assets written to: ../checkpoints\\mymodel_1\\assets\n",
      "147/147 [==============================] - 10s 67ms/step - loss: 5.3909 - RMSE: 1.1231 - val_loss: 5.2668 - val_RMSE: 1.1246\n",
      "Epoch 2/65\n",
      "147/147 [==============================] - ETA: 0s - loss: 5.1441 - RMSE: 1.1201\n",
      "Epoch 00002: val_RMSE improved from 1.12457 to 1.12152, saving model to ../checkpoints\\mymodel_2\n",
      "INFO:tensorflow:Assets written to: ../checkpoints\\mymodel_2\\assets\n",
      "147/147 [==============================] - 9s 63ms/step - loss: 5.1441 - RMSE: 1.1201 - val_loss: 5.0273 - val_RMSE: 1.1215\n",
      "Epoch 3/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 4.9116 - RMSE: 1.1167\n",
      "Epoch 00003: val_RMSE improved from 1.12152 to 1.11846, saving model to ../checkpoints\\mymodel_3\n",
      "INFO:tensorflow:Assets written to: ../checkpoints\\mymodel_3\\assets\n",
      "147/147 [==============================] - 9s 62ms/step - loss: 4.9112 - RMSE: 1.1167 - val_loss: 4.8014 - val_RMSE: 1.1185\n",
      "Epoch 4/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 4.6917 - RMSE: 1.1133\n",
      "Epoch 00004: val_RMSE improved from 1.11846 to 1.11479, saving model to ../checkpoints\\mymodel_4\n",
      "INFO:tensorflow:Assets written to: ../checkpoints\\mymodel_4\\assets\n",
      "147/147 [==============================] - 10s 65ms/step - loss: 4.6914 - RMSE: 1.1135 - val_loss: 4.5877 - val_RMSE: 1.1148\n",
      "Epoch 5/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 4.4835 - RMSE: 1.1092\n",
      "Epoch 00005: val_RMSE improved from 1.11479 to 1.11022, saving model to ../checkpoints\\mymodel_5\n",
      "INFO:tensorflow:Assets written to: ../checkpoints\\mymodel_5\\assets\n",
      "147/147 [==============================] - 9s 61ms/step - loss: 4.4832 - RMSE: 1.1091 - val_loss: 4.3851 - val_RMSE: 1.1102\n",
      "Epoch 6/65\n",
      "147/147 [==============================] - ETA: 0s - loss: 4.2858 - RMSE: 1.1039\n",
      "Epoch 00006: val_RMSE improved from 1.11022 to 1.10465, saving model to ../checkpoints\\mymodel_6\n",
      "INFO:tensorflow:Assets written to: ../checkpoints\\mymodel_6\\assets\n",
      "147/147 [==============================] - 9s 62ms/step - loss: 4.2858 - RMSE: 1.1039 - val_loss: 4.1930 - val_RMSE: 1.1046\n",
      "Epoch 7/65\n",
      "147/147 [==============================] - ETA: 0s - loss: 4.0982 - RMSE: 1.0976\n",
      "Epoch 00007: val_RMSE improved from 1.10465 to 1.09753, saving model to ../checkpoints\\mymodel_7\n",
      "INFO:tensorflow:Assets written to: ../checkpoints\\mymodel_7\\assets\n",
      "147/147 [==============================] - 9s 64ms/step - loss: 4.0982 - RMSE: 1.0976 - val_loss: 4.0102 - val_RMSE: 1.0975\n",
      "Epoch 8/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 3.9191 - RMSE: 1.0888\n",
      "Epoch 00008: val_RMSE improved from 1.09753 to 1.08769, saving model to ../checkpoints\\mymodel_8\n",
      "INFO:tensorflow:Assets written to: ../checkpoints\\mymodel_8\\assets\n",
      "147/147 [==============================] - 9s 62ms/step - loss: 3.9188 - RMSE: 1.0887 - val_loss: 3.8349 - val_RMSE: 1.0877\n",
      "Epoch 9/65\n",
      "147/147 [==============================] - ETA: 0s - loss: 3.7466 - RMSE: 1.0771\n",
      "Epoch 00009: val_RMSE improved from 1.08769 to 1.07621, saving model to ../checkpoints\\mymodel_9\n",
      "INFO:tensorflow:Assets written to: ../checkpoints\\mymodel_9\\assets\n",
      "147/147 [==============================] - 9s 64ms/step - loss: 3.7466 - RMSE: 1.0771 - val_loss: 3.6675 - val_RMSE: 1.0762\n",
      "Epoch 10/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 3.5813 - RMSE: 1.0630\n",
      "Epoch 00010: val_RMSE improved from 1.07621 to 1.06065, saving model to ../checkpoints\\mymodel_10\n",
      "INFO:tensorflow:Assets written to: ../checkpoints\\mymodel_10\\assets\n",
      "147/147 [==============================] - 9s 63ms/step - loss: 3.5809 - RMSE: 1.0626 - val_loss: 3.5052 - val_RMSE: 1.0607\n",
      "Epoch 11/65\n",
      "147/147 [==============================] - ETA: 0s - loss: 3.4217 - RMSE: 1.0460\n",
      "Epoch 00011: val_RMSE improved from 1.06065 to 1.04290, saving model to ../checkpoints\\mymodel_11\n",
      "INFO:tensorflow:Assets written to: ../checkpoints\\mymodel_11\\assets\n",
      "147/147 [==============================] - 10s 66ms/step - loss: 3.4217 - RMSE: 1.0460 - val_loss: 3.3492 - val_RMSE: 1.0429\n",
      "Epoch 12/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 3.2696 - RMSE: 1.0280\n",
      "Epoch 00012: val_RMSE improved from 1.04290 to 1.02556, saving model to ../checkpoints\\mymodel_12\n",
      "INFO:tensorflow:Assets written to: ../checkpoints\\mymodel_12\\assets\n",
      "147/147 [==============================] - 9s 64ms/step - loss: 3.2694 - RMSE: 1.0282 - val_loss: 3.2015 - val_RMSE: 1.0256\n",
      "Epoch 13/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 3.1258 - RMSE: 1.0110\n",
      "Epoch 00013: val_RMSE improved from 1.02556 to 1.01012, saving model to ../checkpoints\\mymodel_13\n",
      "INFO:tensorflow:Assets written to: ../checkpoints\\mymodel_13\\assets\n",
      "147/147 [==============================] - 10s 66ms/step - loss: 3.1256 - RMSE: 1.0110 - val_loss: 3.0631 - val_RMSE: 1.0101\n",
      "Epoch 14/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 2.9911 - RMSE: 0.9958\n",
      "Epoch 00014: val_RMSE improved from 1.01012 to 0.99796, saving model to ../checkpoints\\mymodel_14\n",
      "INFO:tensorflow:Assets written to: ../checkpoints\\mymodel_14\\assets\n",
      "147/147 [==============================] - 10s 66ms/step - loss: 2.9907 - RMSE: 0.9954 - val_loss: 2.9348 - val_RMSE: 0.9980\n",
      "Epoch 15/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 2.8652 - RMSE: 0.9828\n",
      "Epoch 00015: val_RMSE improved from 0.99796 to 0.98651, saving model to ../checkpoints\\mymodel_15\n",
      "INFO:tensorflow:Assets written to: ../checkpoints\\mymodel_15\\assets\n",
      "147/147 [==============================] - 10s 69ms/step - loss: 2.8648 - RMSE: 0.9824 - val_loss: 2.8138 - val_RMSE: 0.9865\n",
      "Epoch 16/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 2.7477 - RMSE: 0.9718\n",
      "Epoch 00016: val_RMSE improved from 0.98651 to 0.97765, saving model to ../checkpoints\\mymodel_16\n",
      "INFO:tensorflow:Assets written to: ../checkpoints\\mymodel_16\\assets\n",
      "147/147 [==============================] - 10s 71ms/step - loss: 2.7476 - RMSE: 0.9721 - val_loss: 2.7015 - val_RMSE: 0.9776\n",
      "Epoch 17/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 2.6389 - RMSE: 0.9636\n",
      "Epoch 00017: val_RMSE improved from 0.97765 to 0.97327, saving model to ../checkpoints\\mymodel_17\n",
      "INFO:tensorflow:Assets written to: ../checkpoints\\mymodel_17\\assets\n",
      "147/147 [==============================] - 9s 62ms/step - loss: 2.6386 - RMSE: 0.9633 - val_loss: 2.5995 - val_RMSE: 0.9733\n",
      "Epoch 18/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 2.5364 - RMSE: 0.9560\n",
      "Epoch 00018: val_RMSE improved from 0.97327 to 0.96704, saving model to ../checkpoints\\mymodel_18\n",
      "INFO:tensorflow:Assets written to: ../checkpoints\\mymodel_18\\assets\n",
      "147/147 [==============================] - 10s 66ms/step - loss: 2.5362 - RMSE: 0.9560 - val_loss: 2.5011 - val_RMSE: 0.9670\n",
      "Epoch 19/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 2.4404 - RMSE: 0.9495\n",
      "Epoch 00019: val_RMSE improved from 0.96704 to 0.96265, saving model to ../checkpoints\\mymodel_19\n",
      "INFO:tensorflow:Assets written to: ../checkpoints\\mymodel_19\\assets\n",
      "147/147 [==============================] - 10s 66ms/step - loss: 2.4403 - RMSE: 0.9497 - val_loss: 2.4098 - val_RMSE: 0.9627\n",
      "Epoch 20/65\n",
      "147/147 [==============================] - ETA: 0s - loss: 2.3528 - RMSE: 0.9464\n",
      "Epoch 00020: val_RMSE improved from 0.96265 to 0.95667, saving model to ../checkpoints\\mymodel_20\n",
      "INFO:tensorflow:Assets written to: ../checkpoints\\mymodel_20\\assets\n",
      "147/147 [==============================] - 10s 69ms/step - loss: 2.3528 - RMSE: 0.9464 - val_loss: 2.3219 - val_RMSE: 0.9567\n",
      "Epoch 21/65\n",
      "147/147 [==============================] - ETA: 0s - loss: 2.2700 - RMSE: 0.9433\n",
      "Epoch 00021: val_RMSE improved from 0.95667 to 0.95618, saving model to ../checkpoints\\mymodel_21\n",
      "INFO:tensorflow:Assets written to: ../checkpoints\\mymodel_21\\assets\n",
      "147/147 [==============================] - 10s 71ms/step - loss: 2.2700 - RMSE: 0.9433 - val_loss: 2.2442 - val_RMSE: 0.9562\n",
      "Epoch 22/65\n",
      "147/147 [==============================] - ETA: 0s - loss: 2.1925 - RMSE: 0.9411\n",
      "Epoch 00022: val_RMSE did not improve from 0.95618\n",
      "147/147 [==============================] - 8s 57ms/step - loss: 2.1925 - RMSE: 0.9411 - val_loss: 2.1783 - val_RMSE: 0.9631\n",
      "Epoch 23/65\n",
      "147/147 [==============================] - ETA: 0s - loss: 2.1238 - RMSE: 0.9427\n",
      "Epoch 00023: val_RMSE did not improve from 0.95618\n",
      "147/147 [==============================] - 9s 59ms/step - loss: 2.1238 - RMSE: 0.9427 - val_loss: 2.1111 - val_RMSE: 0.9646\n",
      "Epoch 24/65\n",
      "147/147 [==============================] - ETA: 0s - loss: 2.0533 - RMSE: 0.9389\n",
      "Epoch 00024: val_RMSE improved from 0.95618 to 0.95533, saving model to ../checkpoints\\mymodel_24\n",
      "INFO:tensorflow:Assets written to: ../checkpoints\\mymodel_24\\assets\n",
      "147/147 [==============================] - 10s 69ms/step - loss: 2.0533 - RMSE: 0.9389 - val_loss: 2.0371 - val_RMSE: 0.9553\n",
      "Epoch 25/65\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.9962 - RMSE: 0.9451\n",
      "Epoch 00025: val_RMSE improved from 0.95533 to 0.94757, saving model to ../checkpoints\\mymodel_25\n",
      "INFO:tensorflow:Assets written to: ../checkpoints\\mymodel_25\\assets\n",
      "147/147 [==============================] - 11s 76ms/step - loss: 1.9962 - RMSE: 0.9451 - val_loss: 1.9684 - val_RMSE: 0.9476\n",
      "Epoch 26/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 1.9316 - RMSE: 0.9393\n",
      "Epoch 00026: val_RMSE improved from 0.94757 to 0.94664, saving model to ../checkpoints\\mymodel_26\n",
      "INFO:tensorflow:Assets written to: ../checkpoints\\mymodel_26\\assets\n",
      "147/147 [==============================] - 10s 71ms/step - loss: 1.9314 - RMSE: 0.9391 - val_loss: 1.9101 - val_RMSE: 0.9466\n",
      "Epoch 27/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 1.8765 - RMSE: 0.9400\n",
      "Epoch 00027: val_RMSE did not improve from 0.94664\n",
      "147/147 [==============================] - 8s 54ms/step - loss: 1.8764 - RMSE: 0.9401 - val_loss: 1.9143 - val_RMSE: 1.0050\n",
      "Epoch 28/65\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.8211 - RMSE: 0.9372\n",
      "Epoch 00028: val_RMSE did not improve from 0.94664\n",
      "147/147 [==============================] - 9s 59ms/step - loss: 1.8211 - RMSE: 0.9372 - val_loss: 1.8069 - val_RMSE: 0.9488\n",
      "Epoch 29/65\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.7727 - RMSE: 0.9386\n",
      "Epoch 00029: val_RMSE did not improve from 0.94664\n",
      "147/147 [==============================] - 8s 53ms/step - loss: 1.7727 - RMSE: 0.9386 - val_loss: 1.8142 - val_RMSE: 1.0042\n",
      "Epoch 30/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 1.7301 - RMSE: 0.9426\n",
      "Epoch 00030: val_RMSE improved from 0.94664 to 0.94323, saving model to ../checkpoints\\mymodel_30\n",
      "INFO:tensorflow:Assets written to: ../checkpoints\\mymodel_30\\assets\n",
      "147/147 [==============================] - 10s 68ms/step - loss: 1.7301 - RMSE: 0.9429 - val_loss: 1.7078 - val_RMSE: 0.9432\n",
      "Epoch 31/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 1.6789 - RMSE: 0.9356\n",
      "Epoch 00031: val_RMSE did not improve from 0.94323\n",
      "147/147 [==============================] - 8s 56ms/step - loss: 1.6789 - RMSE: 0.9358 - val_loss: 1.6716 - val_RMSE: 0.9498\n",
      "Epoch 32/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 1.6360 - RMSE: 0.9343\n",
      "Epoch 00032: val_RMSE did not improve from 0.94323\n",
      "147/147 [==============================] - 8s 55ms/step - loss: 1.6361 - RMSE: 0.9345 - val_loss: 1.6404 - val_RMSE: 0.9590\n",
      "Epoch 33/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 1.6015 - RMSE: 0.9391\n",
      "Epoch 00033: val_RMSE did not improve from 0.94323\n",
      "147/147 [==============================] - 8s 54ms/step - loss: 1.6016 - RMSE: 0.9394 - val_loss: 1.5903 - val_RMSE: 0.9470\n",
      "Epoch 34/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 1.5623 - RMSE: 0.9368\n",
      "Epoch 00034: val_RMSE improved from 0.94323 to 0.94181, saving model to ../checkpoints\\mymodel_34\n",
      "INFO:tensorflow:Assets written to: ../checkpoints\\mymodel_34\\assets\n",
      "147/147 [==============================] - 9s 63ms/step - loss: 1.5623 - RMSE: 0.9370 - val_loss: 1.5492 - val_RMSE: 0.9418\n",
      "Epoch 35/65\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.5195 - RMSE: 0.9290\n",
      "Epoch 00035: val_RMSE did not improve from 0.94181\n",
      "147/147 [==============================] - 8s 54ms/step - loss: 1.5195 - RMSE: 0.9290 - val_loss: 1.5284 - val_RMSE: 0.9549\n",
      "Epoch 36/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 1.4885 - RMSE: 0.9309\n",
      "Epoch 00036: val_RMSE improved from 0.94181 to 0.94035, saving model to ../checkpoints\\mymodel_36\n",
      "INFO:tensorflow:Assets written to: ../checkpoints\\mymodel_36\\assets\n",
      "147/147 [==============================] - 10s 70ms/step - loss: 1.4884 - RMSE: 0.9308 - val_loss: 1.4818 - val_RMSE: 0.9403\n",
      "Epoch 37/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 1.4600 - RMSE: 0.9335\n",
      "Epoch 00037: val_RMSE did not improve from 0.94035\n",
      "147/147 [==============================] - 8s 57ms/step - loss: 1.4598 - RMSE: 0.9331 - val_loss: 1.4547 - val_RMSE: 0.9434\n",
      "Epoch 38/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 1.4324 - RMSE: 0.9352\n",
      "Epoch 00038: val_RMSE improved from 0.94035 to 0.94034, saving model to ../checkpoints\\mymodel_38\n",
      "INFO:tensorflow:Assets written to: ../checkpoints\\mymodel_38\\assets\n",
      "147/147 [==============================] - 10s 69ms/step - loss: 1.4324 - RMSE: 0.9353 - val_loss: 1.4232 - val_RMSE: 0.9403\n",
      "Epoch 39/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 1.3998 - RMSE: 0.9302\n",
      "Epoch 00039: val_RMSE did not improve from 0.94034\n",
      "147/147 [==============================] - 8s 54ms/step - loss: 1.3996 - RMSE: 0.9300 - val_loss: 1.4190 - val_RMSE: 0.9630\n",
      "Epoch 40/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 1.3780 - RMSE: 0.9345\n",
      "Epoch 00040: val_RMSE did not improve from 0.94034\n",
      "147/147 [==============================] - 8s 55ms/step - loss: 1.3780 - RMSE: 0.9344 - val_loss: 1.3948 - val_RMSE: 0.9640\n",
      "Epoch 41/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 1.3490 - RMSE: 0.9300\n",
      "Epoch 00041: val_RMSE did not improve from 0.94034\n",
      "147/147 [==============================] - 8s 56ms/step - loss: 1.3489 - RMSE: 0.9299 - val_loss: 1.3699 - val_RMSE: 0.9629\n",
      "Epoch 42/65\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.3288 - RMSE: 0.9330\n",
      "Epoch 00042: val_RMSE did not improve from 0.94034\n",
      "147/147 [==============================] - 8s 52ms/step - loss: 1.3288 - RMSE: 0.9330 - val_loss: 1.3497 - val_RMSE: 0.9652\n",
      "Epoch 43/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 1.3022 - RMSE: 0.9282\n",
      "Epoch 00043: val_RMSE did not improve from 0.94034\n",
      "147/147 [==============================] - 8s 54ms/step - loss: 1.3024 - RMSE: 0.9286 - val_loss: 1.3041 - val_RMSE: 0.9409\n",
      "Epoch 44/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 1.2814 - RMSE: 0.9281\n",
      "Epoch 00044: val_RMSE did not improve from 0.94034\n",
      "147/147 [==============================] - 8s 57ms/step - loss: 1.2813 - RMSE: 0.9279 - val_loss: 1.2841 - val_RMSE: 0.9409\n",
      "Epoch 45/65\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.2716 - RMSE: 0.9378\n",
      "Epoch 00045: val_RMSE did not improve from 0.94034\n",
      "147/147 [==============================] - 8s 55ms/step - loss: 1.2716 - RMSE: 0.9378 - val_loss: 1.3582 - val_RMSE: 1.0338\n",
      "Epoch 46/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 1.2474 - RMSE: 0.9317\n",
      "Epoch 00046: val_RMSE improved from 0.94034 to 0.93918, saving model to ../checkpoints\\mymodel_46\n",
      "INFO:tensorflow:Assets written to: ../checkpoints\\mymodel_46\\assets\n",
      "147/147 [==============================] - 10s 67ms/step - loss: 1.2472 - RMSE: 0.9314 - val_loss: 1.2458 - val_RMSE: 0.9392\n",
      "Epoch 47/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 1.2285 - RMSE: 0.9301\n",
      "Epoch 00047: val_RMSE did not improve from 0.93918\n",
      "147/147 [==============================] - 9s 59ms/step - loss: 1.2284 - RMSE: 0.9300 - val_loss: 1.2469 - val_RMSE: 0.9571\n",
      "Epoch 48/65\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.2127 - RMSE: 0.9304\n",
      "Epoch 00048: val_RMSE did not improve from 0.93918\n",
      "147/147 [==============================] - 8s 57ms/step - loss: 1.2127 - RMSE: 0.9304 - val_loss: 1.2199 - val_RMSE: 0.9459\n",
      "Epoch 49/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 1.1936 - RMSE: 0.9269\n",
      "Epoch 00049: val_RMSE did not improve from 0.93918\n",
      "147/147 [==============================] - 9s 59ms/step - loss: 1.1935 - RMSE: 0.9267 - val_loss: 1.2014 - val_RMSE: 0.9423\n",
      "Epoch 50/65\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.1798 - RMSE: 0.9276\n",
      "Epoch 00050: val_RMSE did not improve from 0.93918\n",
      "147/147 [==============================] - 8s 53ms/step - loss: 1.1798 - RMSE: 0.9276 - val_loss: 1.2019 - val_RMSE: 0.9569\n",
      "Epoch 51/65\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.1706 - RMSE: 0.9320\n",
      "Epoch 00051: val_RMSE did not improve from 0.93918\n",
      "147/147 [==============================] - 8s 54ms/step - loss: 1.1706 - RMSE: 0.9320 - val_loss: 1.1712 - val_RMSE: 0.9394\n",
      "Epoch 52/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 1.1558 - RMSE: 0.9302\n",
      "Epoch 00052: val_RMSE did not improve from 0.93918\n",
      "147/147 [==============================] - 8s 56ms/step - loss: 1.1560 - RMSE: 0.9306 - val_loss: 1.1845 - val_RMSE: 0.9653\n",
      "Epoch 53/65\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.1409 - RMSE: 0.9275\n",
      "Epoch 00053: val_RMSE did not improve from 0.93918\n",
      "147/147 [==============================] - 8s 56ms/step - loss: 1.1409 - RMSE: 0.9275 - val_loss: 1.1469 - val_RMSE: 0.9395\n",
      "Epoch 54/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 1.1310 - RMSE: 0.9291\n",
      "Epoch 00054: val_RMSE did not improve from 0.93918\n",
      "147/147 [==============================] - 8s 53ms/step - loss: 1.1310 - RMSE: 0.9291 - val_loss: 1.1486 - val_RMSE: 0.9524\n",
      "Epoch 55/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 1.1219 - RMSE: 0.9309\n",
      "Epoch 00055: val_RMSE did not improve from 0.93918\n",
      "147/147 [==============================] - 8s 56ms/step - loss: 1.1220 - RMSE: 0.9310 - val_loss: 1.1360 - val_RMSE: 0.9502\n",
      "Epoch 56/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 1.1069 - RMSE: 0.9260\n",
      "Epoch 00056: val_RMSE did not improve from 0.93918\n",
      "147/147 [==============================] - 8s 55ms/step - loss: 1.1069 - RMSE: 0.9261 - val_loss: 1.1281 - val_RMSE: 0.9523\n",
      "Epoch 57/65\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.1018 - RMSE: 0.9303\n",
      "Epoch 00057: val_RMSE did not improve from 0.93918\n",
      "147/147 [==============================] - 8s 56ms/step - loss: 1.1018 - RMSE: 0.9303 - val_loss: 1.1076 - val_RMSE: 0.9411\n",
      "Epoch 58/65\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.0917 - RMSE: 0.9292\n",
      "Epoch 00058: val_RMSE did not improve from 0.93918\n",
      "147/147 [==============================] - 8s 55ms/step - loss: 1.0917 - RMSE: 0.9292 - val_loss: 1.0972 - val_RMSE: 0.9395\n",
      "Epoch 59/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 1.0798 - RMSE: 0.9262\n",
      "Epoch 00059: val_RMSE did not improve from 0.93918\n",
      "147/147 [==============================] - 8s 53ms/step - loss: 1.0796 - RMSE: 0.9258 - val_loss: 1.0935 - val_RMSE: 0.9442\n",
      "Epoch 60/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 1.0712 - RMSE: 0.9258\n",
      "Epoch 00060: val_RMSE did not improve from 0.93918\n",
      "147/147 [==============================] - 8s 57ms/step - loss: 1.0712 - RMSE: 0.9258 - val_loss: 1.1484 - val_RMSE: 1.0069\n",
      "Epoch 61/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 1.0683 - RMSE: 0.9304\n",
      "Epoch 00061: val_RMSE did not improve from 0.93918\n",
      "147/147 [==============================] - 8s 56ms/step - loss: 1.0683 - RMSE: 0.9305 - val_loss: 1.1031 - val_RMSE: 0.9691\n",
      "Epoch 62/65\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.0587 - RMSE: 0.9277\n",
      "Epoch 00062: val_RMSE did not improve from 0.93918\n",
      "147/147 [==============================] - 8s 55ms/step - loss: 1.0587 - RMSE: 0.9277 - val_loss: 1.0763 - val_RMSE: 0.9492\n",
      "Epoch 63/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 1.0542 - RMSE: 0.9302\n",
      "Epoch 00063: val_RMSE did not improve from 0.93918\n",
      "147/147 [==============================] - 8s 58ms/step - loss: 1.0541 - RMSE: 0.9301 - val_loss: 1.0630 - val_RMSE: 0.9424\n",
      "Epoch 64/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 1.0481 - RMSE: 0.9306\n",
      "Epoch 00064: val_RMSE did not improve from 0.93918\n",
      "147/147 [==============================] - 8s 55ms/step - loss: 1.0480 - RMSE: 0.9303 - val_loss: 1.0697 - val_RMSE: 0.9553\n",
      "Epoch 65/65\n",
      "146/147 [============================>.] - ETA: 0s - loss: 1.0361 - RMSE: 0.9246\n",
      "Epoch 00065: val_RMSE did not improve from 0.93918\n",
      "147/147 [==============================] - 8s 55ms/step - loss: 1.0360 - RMSE: 0.9243 - val_loss: 1.0489 - val_RMSE: 0.9404\n"
     ]
    }
   ],
   "source": [
    "resut = mode.fit(\n",
    "  x=[ratings_train.user_id.vaues, ratings_train.wineCode.vaues, ratings_train.sex.vaues,ratings_train.age.vaues],\n",
    "  y=ratings_train.rating.vaues - mu,\n",
    "  epochs=65,\n",
    "  batch_size=512,\n",
    "  vaidation_data=(\n",
    "    [ratings_test.user_id.vaues, ratings_test.wineCode.vaues, ratings_test.age.vaues,ratings_test.sex.vaues],\n",
    "    ratings_test.rating.vaues - mu\n",
    "  ),\n",
    "   cabacks=[cabacks]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matpotib.pypot as pt\n",
    "pt.pot(resut.history['RMSE'], abe=\"Train RMSE\")\n",
    "pt.pot(resut.history['va_RMSE'], abe=\"Test RMSE\")\n",
    "pt.xabe('epoch')\n",
    "pt.yabe('RMSE')\n",
    "pt.egend()\n",
    "pt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode.save_weights('../checkpoints/ast_mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode2 = Mode(inputs=[user, item, age], outputs=R)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 1, 200)       188800      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 1, 200)       336600      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 1, 1)         944         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, 1, 1)         1683        ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)        (None, 1, 3)         63          ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 200)          0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 200)          0           ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 1)            0           ['embedding_2[0][0]']            \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 1)            0           ['embedding_3[0][0]']            \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 3)            0           ['embedding_4[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 405)          0           ['flatten[0][0]',                \n",
      "                                                                  'flatten_1[0][0]',              \n",
      "                                                                  'flatten_2[0][0]',              \n",
      "                                                                  'flatten_3[0][0]',              \n",
      "                                                                  'flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 2048)         831488      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 2048)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1024)         2098176     ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 1024)         0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 512)          524800      ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 512)          0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 256)          131328      ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 256)          0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 1)            257         ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,114,139\n",
      "Trainable params: 4,114,139\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mode2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shapes (1024,) and (256,) are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20180/1876314936.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../checkpoints/mymodel_63/variables/variables'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\py38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   1169\u001b[0m     \"\"\"\n\u001b[0;32m   1170\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1171\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Shapes %s and %s are incompatible\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1173\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mmost_specific_compatible_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shapes (1024,) and (256,) are incompatible"
     ]
    }
   ],
   "source": [
    "mode2.load_weights('../checkpoints/mymode_63/variabes/variabes')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "db7a06b0252abda3d2699e6572f746b881947a2ae64608408482929be106f278"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('py38': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
